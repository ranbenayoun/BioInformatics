---
title: "Homework 1"
author: "<206078974>_<315831321>"
date: "`r Sys.Date()`"
output: html_document
---

In the following tasks you will use statistics and sequence alignment to analyze real COVID-19 world data.

- Load packages
```{r message=TRUE, warning=TRUE, include=FALSE}
library(tidyverse)
library(ggplot2)
library(Biostrings)
library(msa)
library(msaR)
library(ggpubr) # For adding the p-value annotation
library(seqinr)
```

- Set your working directory
```{r include=FALSE}
#setwd("HW1")
```


## Task 1: Data Exploration, Cleaning, and Preparation

This task involves exploring the dataset, identifying missing or irrelevant data, and cleaning the dataset for further analysis.

### Step 1: Load the Dataset

Load the dataset `COVID19_line_list_data.csv` into R.

```{r load-data}
# Load the dataset and inspect the first few rows
covid_data <- read.csv("COVID19_line_list_data.csv")
```

### Step 2: Basic Dataset Overview

- How many rows and columns are in the dataset?
- What are the column names?

```{r dataset-overview}
# Write code to find the dimensions and column names
dataset_dimensions <- dim(covid_data)
column_names <- colnames(covid_data)

cat("The dataset has", dataset_dimensions[1], "rows and", dataset_dimensions[2], "columns.\n")
cat("The column names are:\n")
print(column_names)
```

### Step 3: Identify Missing Data

- Calculate the percentage of missing values for each column.
- Visualize missing data with a bar plot.

```{r missing-data}
# Write code to calculate and visualize missing data

# Calculate the percentage of missing values for each column in covid_data
missing_percentage <- colSums(is.na(covid_data)) / nrow(covid_data) * 100

# Create a data frame for visualization
missing_data <- data.frame(
  Column = names(missing_percentage),
  MissingPercentage = missing_percentage
)

# Visualize the missing data with a bar plot
ggplot(missing_data, aes(x = Column, y = MissingPercentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Percentage of Missing Values by Column in COVID Data",
    x = "Column",
    y = "Missing Percentage (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### Step 4: Handle Missing Data

- Identify columns with more than 50% missing data and remove them.

```{r handle-missing-data}
# Write code to handle missing data

# Ensure the dataset is a tibble for tidyverse compatibility
covid_data <- as_tibble(covid_data)

# Calculate the percentage of missing values for each column
missing_percentage <- covid_data %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100)) %>%
  pivot_longer(everything(), names_to = "column", values_to = "missing_percentage")

# Identify columns with more than 50% missing data
columns_to_remove <- missing_percentage %>%
  filter(missing_percentage > 50) %>%
  pull(column)

# Remove columns with more than 50% missing data using dplyr explicitly
covid_data_cleaned <- covid_data %>%
  dplyr::select(-all_of(columns_to_remove))

# Print the names of removed columns
cat("Removed columns with more than 50% missing data:", paste(columns_to_remove, collapse = ", "), "\n")

# Summary of the cleaned dataset
print(dim(covid_data_cleaned))
```

### Step 5: Convert Date Columns to Proper Format

- Convert `reporting date` and `symptom onset` columns to date format.
- Create a new column calculating the difference between `reporting date` and `symptom onset`.
Note: Some dates state the year as 19/20 instead of 2019/2020
```{r date-conversion}
# Write code to convert date columns and calculate the difference
covid_data_cleaned <- covid_data_cleaned %>%
  mutate(
    reporting_date = as.Date(sub("(\\d{2})$", "20\\1", reporting.date), format = "%m/%d/%Y"),
    symptom_onset = as.Date(sub("(\\d{2})$", "20\\1", symptom_onset), format = "%m/%d/%Y"),
    date_difference = as.numeric(reporting_date - symptom_onset)
  )

head(covid_data_cleaned)
```

### Step 6: Summary Statistics of Cleaned Data

- Generate summary statistics (mean, median, min, max) for numeric columns.
- Count the number of cases by gender.

```{r summary-stats}
# Write code to generate summary statistics
numeric_summary <- summary(covid_data_cleaned[sapply(covid_data_cleaned, is.numeric)])
print(numeric_summary)

# Count cases by gender
gender_count <- table(covid_data_cleaned$gender)
print(gender_count)

```

### Step 7: Data Visualization

- Create a histogram to visualize the distribution of ages in the dataset.
- Generate a bar plot to show the number of cases by gender.

```{r data-visualization}
# Write code to create the histogram and bar plot
par(mfrow = c(1, 2))  # Split plot area into 1 row and 2 columns

# Histogram
hist(covid_data_cleaned$age,  main = "Age Distribution",  xlab = "Age",  col = "lightblue",  las = 1)

# Bar Plot
barplot(gender_count, main = "Number of Cases by Gender", xlab = "Gender", ylab = "Number of Cases", col = c("lightpink", "lightblue"),  las = 1)

par(mfrow = c(1, 1))  # Reset plot area to single plot

```

### Step 8: Filter Data for Specific Conditions

- Filter the dataset to include only cases from China where the patient has recovered.
- Calculate the average age of recovered patients in this subset.

```{r filter-data}
# Write code to filter data and calculate the average age

average_age <- covid_data_cleaned %>%
  filter(country == "China", recovered == 1) %>%
  summarize(avg_age = mean(age, na.rm = TRUE)) %>%
  pull(avg_age)

print(paste("The average age of recovered patients in China is:", round(average_age, 2)))

```

## Task 2: Statistical Analysis

This task involves testing a hypothesis related to COVID-19 data. The goal is to assess whether the average age of patients who recovered differs significantly from those who did not recover.

### Step 1: Formulate the Hypothesis

Before running the test, answer the following in free text:

1. **What is the null hypothesis?**  
2. **What is the alternative hypothesis?**  
3. **What type of data are we working with? (e.g., categorical, numerical, etc.)**  
4. **How do we assess the normality of the data?**  
5. **How should the test statistics and p-value be interpreted?**

**Write your answers here as free text:** <br />
1. Null Hypothesis(H_0): there is no significant difference between the average age of patients who recovered and the patients who didn't recover.<br />
2. Alternative Hypothesis (H_1): there is a difference between the average age of the patients who recovered and those who didn't. <br />
3. Age is numerical, and recovery is categorical (healthy/sick is 0/1). <br />
4. We can preform a statistical test such as Shapiro-Wilk or try to assess visually from the distribution. <br />
5. For a high t-statistic, and a low p-value (less than 0.025 as we do two-sided) will reject the null hypothesis and say there is a difference between the age of the recovered. else, we can't reject the hypothesis and we can't say there is a difference.

### Step 2: Data Preparation

- Filter the data into two groups: recovered and non-recovered patients.
- Remove rows with missing values in the `age` column.
Note: Any value other than zero in the "recovered" column means that the patient didn't die.

```{r data-prep}
# Write code to filter and clean the data
# Remove rows with missing values in the `age` column and filter into two groups
covid_data_cleaned <- covid_data_cleaned %>%
  drop_na(age) %>%  
  mutate(
    group = if_else(recovered != 0, "Recovered", "Non-Recovered")
  )

# Split into two separate data frames
recovered_patients <- covid_data_cleaned %>%
  filter(group == "Recovered")

non_recovered_patients <- covid_data_cleaned %>%
  filter(group == "Non-Recovered")

# View the datasets
head(covid_data_cleaned)
head(recovered_patients)
head(non_recovered_patients)
```

### Step 3: Assess Normality

- Use a histogram and a Shapiro-Wilk test to assess the normality of age distribution for both groups.

```{r normality-test}
# Write code to assess normality
# Plot histograms for age distribution
recovered_patients %>%
  ggplot(aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "white", alpha = 0.7) +
  labs(title = "Age Distribution for Recovered Patients",
       x = "Age",
       y = "Count") +
  theme_minimal()

non_recovered_patients %>%
  ggplot(aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "red", color = "white", alpha = 0.7) +
  labs(title = "Age Distribution for Non-Recovered Patients",
       x = "Age",
       y = "Count") +
  theme_minimal()

# Perform Shapiro-Wilk test for age distribution
recovered_age_test <- shapiro.test(recovered_patients$age)
non_recovered_age_test <- shapiro.test(non_recovered_patients$age)

# Print test results
print("Shapiro-Wilk Test for Recovered Patients:")
print(recovered_age_test)

print("Shapiro-Wilk Test for Non-Recovered Patients:")
print(non_recovered_age_test)
```

1. **Does the Shapiro-Wilk test results indicated that the data follow a normal distributions?**  
2. **How does it affect our choice of statistical test?**  

**Write your answers here as free text:** <br />
1. The Shapiro-Wilk null hypothesis assumes the data is normally distributed, non-recovered patients p-value is smaller than 0.05 so we reject the null hypothesis and can't say the data is normally distributed.
in the case of recovered patients, the p-value is a bit above 0.05 so we might say it can't reject the null hypothesis and the data is normally distributed, but with such a small difference it's debatable. <br />
2. All in all, we won't assume the data is normally distributed, as one group's test score clearly isn't and the other is questionable. we can see the histogram shape can be misleading sometimes and we must not relay solely on it. we will have to choose a statistic test that does not assume normal distribution.

### Step 4: Perform a Mann-Whitney U Test

```{r mann-whitney-test}
# Write code to perform a Mann-Whitney U test
# Perform the Mann-Whitney U test (Wilcoxon rank-sum test in R)
mann_whitney_test <- wilcox.test(recovered_patients$age, non_recovered_patients$age,  paired = FALSE, alternative = "two.sided")

# Print the test results
print("Mann-Whitney U Test Results:")
print(mann_whitney_test)
```

### Step 5: Visualize the Results with Boxplots

- Create a boxplot to visualize the age distribution for recovered and non-recovered groups.
- Display the p-value above the boxplot.

```{r boxplot-visualization}
# Write code to create the boxplot and annotate with the p-value

ggplot(covid_data_cleaned, aes(x = group, y = age, fill = group)) +
  geom_boxplot(alpha = 0.7, outlier.color = "red", outlier.size = 2) +
  scale_fill_manual(values = c("Recovered" = "blue", "Non-Recovered" = "red")) +
  labs(
    title = "Age Distribution for Recovered and Non-Recovered Patients",
    x = "Group",
    y = "Age"
  ) +
  theme_minimal() +
  theme(legend.position = "none") +
  stat_compare_means(method = "wilcox.test", label = "p.signif", label.y = max(covid_data_cleaned$age) + 5) + # Annotate p-value
  annotate("text", x = 1.5, y = max(covid_data_cleaned$age) + 10, 
           label = paste("p-value =", signif(mann_whitney_test$p.value, digits = 3)), size = 5)

```

### Step 6: Interpret the Results

In free text, answer the following questions:

1. **Was the null hypothesis rejected?**  
2. **What do the test statistic and p-value tell us?**  
3. **Is there evidence to suggest a difference in mean age between the groups?**  

**Write your answers here as free text:** <br />
1. Yes, we can reject the null hypothesis.  <br />
2. We got p-value below 0.025 for a two-sided test, and a t-statistic in such a high value that shows us there is very little overlap between the age group distributions, so we can distinguish between them.  (W = 37432, p-value = 7.798e-07). <br />
3. We can see in the boxplot the difference in the mean of the ages between the groups. the non-recovered mean's value is the the recovered's Q3. 


## Task 3: Analyzing COVID-19 Mortality and Human Development Index (HDI)

In this task, we will explore the hypothesis that countries with a high Human Development Index (HDI) have a greater risk of dying from COVID-19.

### Step 1: Load the Data

- Read "owid-covid-data.csv" from the URL into a variable called `covid_world`.

```{r}
# Enter your code here:
covid_world <- read.csv("owid-covid-data.csv")
```

### Step 2: Take a Look at the Data

- View the dataset.

```{r include=FALSE}
View(covid_world)
```


### Step 3: Create a Subset for Analysis

- Do the following using pipes ("%>%" or "|>") followed by the correct functions from the `tidyverse` package.
- Make a second table and call it `covid_hdi_vs_deaths`:
  1. Keep rows where `date` is equal to "2021-11-08".
  2. Select the columns: `"location"`, `"human_development_index"`, `"population"`, `"total_deaths"`.
  3. Remove rows with `NA` values.
  4. Add a column `total_deaths_per_million` that normalize the total death in each country per million (round the final value).

```{r}
# Enter your code here:
# Create the subset table 'covid_hdi_vs_deaths'
covid_hdi_vs_deaths <- covid_world %>%
  filter(date == "2021-11-08") %>%  
  select(location, human_development_index, population, total_deaths) %>% 
  drop_na() %>% 
  mutate(total_deaths_per_million = round(total_deaths / population * 1e6, 0))

# View the resulting dataset
head(covid_hdi_vs_deaths)
```


### Step 4: Visualize the Relationship

- Create a scatterplot to visualize the relationship between HDI and `total_deaths_per_million`.
- Add a linear regression line to the plot using `geom_smooth`

```{r}
# Enter your code here:
ggplot(covid_hdi_vs_deaths, aes(x = human_development_index, y = total_deaths_per_million)) +
  geom_point(color = "blue", alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "red") + 
  labs(
    title = "Relationship between HDI and Total Deaths per Million",
    x = "Human Development Index (HDI)",
    y = "Total Deaths per Million"
  ) +
  theme_minimal()
```

### Step 5: Calculate Correlations

- Calculate the **Pearson** and **Spearman** correlation coefficients between HDI and `total_deaths_per_million`.

```{r}
# Enter your code here:
# Calculate Pearson correlation coefficient
pearson_corr <- cor(covid_hdi_vs_deaths$human_development_index, 
                    covid_hdi_vs_deaths$total_deaths_per_million, 
                    method = "pearson")

# Calculate Spearman correlation coefficient
spearman_corr <- cor(covid_hdi_vs_deaths$human_development_index, 
                     covid_hdi_vs_deaths$total_deaths_per_million, 
                     method = "spearman")

# Print the correlation coefficients
cat("Pearson Correlation Coefficient:", pearson_corr, "\n")
cat("Spearman Correlation Coefficient:", spearman_corr, "\n")

```


### Step 6: Interpret the Correlation

- Report the Pearson and Spearman correlation coefficients, the strength (weak/moderate/strong/very strong), and the direction (positive/negative).

**Write your answers here as free text:**
The Pearson coef is +0.5 which presents a positive-moderate strength, and the Spearman is +0.6 which is also positive and shows a bit stronger correlation, both indicate there is a relationship between HDI and total death per million.

### Step 7: Assess the Claim

- Do you agree with the claim that increased HDI causes higher COVID-19 mortality? Write a detailed explanation.

**Write your answers here as free text:** <br />
correlation does not imply causation, so we don't know the nature of the relationship between HDI and COVID mortality.

### Step 8: Find Another Feature

- Find another feature in `covid_world` that might explain the correlation between HDI and COVID-19 mortality.
- Plot this feature as in step 4.


```{r}
# Enter your code here:
# Create the subset table 'covid_hdi_vs_deaths'
covid_age_vs_deaths <- covid_world %>%
  filter(date == "2021-11-08") %>%  
  select(location, median_age, population, total_deaths) %>% 
  drop_na() %>% 
  mutate(total_deaths_per_million = round(total_deaths / population * 1e6, 0))

ggplot(covid_age_vs_deaths, aes(x = median_age, y = total_deaths_per_million)) +
  geom_point(color = "blue", alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "red") + 
  labs(
    title = "Relationship between HDI and Total Deaths per Million",
    x = "Median Age",
    y = "Total Deaths per Million"
  ) +
  theme_minimal()
```

### Step 9: Explain the New Finding

- Write your explanation for the relationship you found.

**Write your answers here as free text:** <br />
We chose "median age", as we saw in Task2 there is a relationship between age and recovery in the previous dataset. we can see in the plot that low median age have less deaths. low median age means the population is generally younger, which might help in COVID recovery. age is a factor calculated in HDI, the higher the age the higher the HDI - so we can hypothesis the age is the contributing factor to the correlation.

## Task 4 - Sequence Alignment

- Take a look at the "Biostrings" package vignettes
```{r include=FALSE}
browseVignettes("Biostrings")
```

- Download the file "covid_spike_variants.fasta" from the course website
This file contain the amino acids sequence of the COVID-19 spike protein from different variants

- Load the file using the correct function from the package "Biostrings" and assign to a variable called "variants"
```{r}
# Enter your code here:
file_path <- "covid_spike_variants.fasta"
variants <- readAAStringSet(file_path)
variants
```

- How many amina acids are in the Alpha variant?

**Write your answers here as free text:** <br />
1270

- Read the documentation for the Multiple Sequence Alignment (msa) function from the package "msa"
- Run MSA for the sequences in "variants" and assign the results to "variants.msa"
```{r}
# Enter your code here:
?msa

variants.msa <- msa(variants)
variants.msa
```


- Take a look at the results using the package "msaR" (notice: you can scroll right and left to see all the sequence)
```{r}
msaR(AAMultipleAlignment(variants.msa), colorscheme = "taylor")
```

- (1) Which amino-acids appear in position #26? (type "AMINO_ACID_CODE" in the console)
- (2) Write an example of a SNP that can cause the change in amino acid as we see in the Gamma variant

**Write your answers here as free text:** <br />
1. we have "P" - Proline, except in the 'Gamma Brazil' varient which has a "S" - Serine. <br />
2. "CCG" having a SNP to turn into "AGC"

Phylogenetic tree for the COVID19 variants:
- Use the package "seqinr" to generate a distance matrix from the MSA results
```{r include=FALSE}
# Enter your code here:
variants.msa.seqinr <- msaConvert(variants.msa, type="seqinr::alignment")
variants.msa.distmat <- seqinr::dist.alignment(variants.msa.seqinr, matrix = "similarity")
variants.msa.distmat
```

- Plot a phylogenetic tree (dendrogram) assembled by hierarchical clustering using the "ward.D" method
```{r}
# Enter your code here:
variants.msa.clusters <- hclust(variants.msa.distmat, method = "ward.D")
plot(variants.msa.clusters, hang = -1, main = "Covid19 Varinats Phylogenetic Tree", xlab = "Variants", ylab  = "Distance")
```


- Look at the phylogenetic tree and answer the following questions:
1. Which variant is most similar to the Beta variant?
2. Which pair of variants are the closest?

**Write your answers here as free text:** <br />
1. the Gamma_Brazil is most similar <br />
2. 19A_China and Epsilon_USA has a distance score of 0.04854521, so they are the closest.

# Instructions to Knit the Homework as an HTML File Before Submission

1. Replace `<ID1>` and `<ID2>` in the YAML header with your student IDs:
   ```yaml
   title: "Homework 1"
   author: "<ID1>_<ID2>"
   date: "`r Sys.Date()`"
   output: html_document
   ```
   Example: `author: "123456789_123456789"`

2. Click the arrow next to the **Knit** button, and click **Knit to HTML**

3. Verify the output and submit the HTML file to the course website