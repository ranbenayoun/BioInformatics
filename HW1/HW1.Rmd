---
title: "Homework 1"
author: "<206078974>_<315831321>"
date: "`r Sys.Date()`"
output: html_document
---

In the following tasks you will use statistics and sequence alignment to analyze real COVID-19 world data.

- Load packages
```{r message=TRUE, warning=TRUE, include=FALSE}
library(tidyverse)
library(Biostrings)
library(msa)
library(msaR)
```

- Set your working directory
```{r include=FALSE}
#setwd("~/Desktop/Masters/Courses/Bioinformatics/HW1")
```


## Task 1: Data Exploration, Cleaning, and Preparation

This task involves exploring the dataset, identifying missing or irrelevant data, and cleaning the dataset for further analysis.

### Step 1: Load the Dataset

Load the dataset `COVID19_line_list_data.csv` into R.

```{r load-data}
library(readr)

# Specify the file path (update the path if necessary)
file_path <- "COVID19_line_list_data.csv"

# Load the dataset
covid_data <- read_csv(file_path)

# Inspect the first few rows of the dataset
head(covid_data)
```

### Step 2: Basic Dataset Overview

- How many rows and columns are in the dataset?
- What are the column names?

```{r dataset-overview}
# Write code to find the dimensions and column names
dataset_dimensions <- dim(covid_data)
column_names <- colnames(covid_data)

cat("The dataset has", dataset_dimensions[1], "rows and", dataset_dimensions[2], "columns.\n")
cat("The column names are:\n")
print(column_names)
```

### Step 3: Identify Missing Data

- Calculate the percentage of missing values for each column.
- Visualize missing data with a bar plot.

```{r missing-data}
# Write code to calculate and visualize missing data
library(ggplot2)

# Calculate the percentage of missing values for each column
missing_percentage <- colSums(is.na(covid_data)) / nrow(covid_data) * 100

# Convert the result into a data frame for visualization
missing_data_df <- data.frame(
  Column = names(missing_percentage),
  MissingPercentage = missing_percentage
)

# Print the missing percentage table for reference
print(missing_data_df)

# Create a bar plot to visualize the missing data
ggplot(missing_data_df, aes(x = reorder(Column, -MissingPercentage), y = MissingPercentage)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Percentage of Missing Values per Column",
    x = "Column",
    y = "Missing Percentage (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Step 4: Handle Missing Data

- Identify columns with more than 50% missing data and remove them.

```{r handle-missing-data}
# Write code to handle missing data
# Calculate the percentage of missing values for each column
missing_percentage <- colSums(is.na(covid_data)) / nrow(covid_data) * 100

# Identify columns with more than 50% missing data
columns_to_remove <- names(missing_percentage[missing_percentage > 50])

# Print the columns to be removed
cat("Columns with more than 50% missing data:\n")
print(columns_to_remove)

# Remove those columns from the dataset
cleaned_data <- covid_data[, !(names(covid_data) %in% columns_to_remove)]

# Print dimensions of the cleaned dataset
cat("The cleaned dataset has", nrow(cleaned_data), "rows and", ncol(cleaned_data), "columns.\n")
```
### Step 5: Convert Date Columns to Proper Format

- Convert `reporting date` and `symptom onset` columns to date format.
- Create a new column calculating the difference between `reporting date` and `symptom onset`.
Note: Some dates state the year as 19/20 instead of 2019/2020
```{r date-conversion}
# Write code to convert date columns and calculate the difference
# Load necessary library for date manipulation
library(lubridate)

# Convert 'reporting date' and 'symptom_onset' to date format
# Adjust for years '19/20' as '2019/2020'

# First, correct the 'year' format for dates (if needed)
covid_data$`reporting date` <- gsub("(19|20)(\\d{2})", "20\\2", covid_data$`reporting date`)
covid_data$`symptom_onset` <- gsub("(19|20)(\\d{2})", "20\\2", covid_data$`symptom_onset`)

# Convert to Date format (assuming 'dd/mm/yyyy' format; adjust if needed)
covid_data$`reporting date` <- dmy(covid_data$`reporting date`, quiet = TRUE)
covid_data$`symptom_onset` <- dmy(covid_data$`symptom_onset`, quiet = TRUE)

# Create a new column calculating the difference in days between reporting date and symptom onset
covid_data$days_diff <- as.numeric(difftime(covid_data$`reporting date`, covid_data$`symptom_onset`, units = "days"))

# Print a summary of the new 'days_diff' column
summary(covid_data$days_diff)
```

### Step 6: Summary Statistics of Cleaned Data

- Generate summary statistics (mean, median, min, max) for numeric columns.
- Count the number of cases by gender.

```{r summary-stats}
# Write code to generate summary statistics
# Generate summary statistics for numeric columns (mean, median, min, max)
numeric_summary <- summary(covid_data[, sapply(covid_data, is.numeric)])

# Print the summary statistics for numeric columns
cat("Summary statistics for numeric columns:\n")
print(numeric_summary)

# Count the number of cases by gender
gender_count <- table(covid_data$gender)

# Print the number of cases by gender
cat("\nNumber of cases by gender:")
print(gender_count)
```

### Step 7: Data Visualization

- Create a histogram to visualize the distribution of ages in the dataset.
- Generate a bar plot to show the number of cases by gender.

```{r data-visualization}
# Write code to create the histogram and bar plot
# Load necessary library for visualization
library(ggplot2)

# Create a histogram to visualize the distribution of ages
ggplot(covid_data, aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(
    title = "Distribution of Ages in the Dataset",
    x = "Age",
    y = "Frequency"
  ) +
  theme_minimal()

# Create a bar plot to show the number of cases by gender
ggplot(covid_data, aes(x = gender)) +
  geom_bar(fill = "steelblue", color = "black", alpha = 0.7) +
  labs(
    title = "Number of Cases by Gender",
    x = "Gender",
    y = "Count"
  ) +
  theme_minimal()
```

### Step 8: Filter Data for Specific Conditions

- Filter the dataset to include only cases from China where the patient has recovered.
- Calculate the average age of recovered patients in this subset.

```{r filter-data}
# Write code to filter data and calculate the average age
# Filter the dataset for cases from China where the patient has recovered
recovered_china <- subset(covid_data, country == "China" & recovered == "1")

# Calculate the average age of recovered patients in this subset
average_age_recovered <- mean(recovered_china$age, na.rm = TRUE)

# Print the average age
cat("The average age of recovered patients in China is:", average_age_recovered, "\n")
```

## Task 2: Statistical Analysis

This task involves testing a hypothesis related to COVID-19 data. The goal is to assess whether the average age of patients who recovered differs significantly from those who did not recover.

### Step 1: Formulate the Hypothesis

Before running the test, answer the following in free text:

1. **What is the null hypothesis?**
2. **What is the alternative hypothesis?**  
3. **What type of data are we working with? (e.g., categorical, numerical, etc.)**
4. **How do we assess the normality of the data?**
5. **How should the test statistics and p-value be interpreted?**

**Write your answers here as free text:**
1. The null hypothesis in this case is that there is no significant difference in the average age between patients who recovered and patients who did not recover.
2. The alternative hypothesis in this case is that there is a significant difference in the average age between patients who recovered and those who did not recover.
3. We are working with numerical data in this case, specifically the age of patients, which is a continuous variable.
The age of patients is a numerical variable that can take any value within a given range (e.g., integers or decimals representing years).
The recovery status (recovered vs. non-recovered) is categorical with two levels: recovered and non-recovered, which will be used to group the patients for comparison.
4. To assess the normality of the age data (for both recovered and non-recovered patients), we typically use a combination of visual inspection and statistical tests.
5. When conducting hypothesis tests (e.g., a t-test, Mann-Whitney U test, or Shapiro-Wilk test), the test statistic and p-value are key to interpreting the results.

### Step 2: Data Preparation

- Filter the data into two groups: recovered and non-recovered patients.
- Remove rows with missing values in the `age` column.
Note: Any value other than zero in the "recovered" column means that the patient didn't die.

```{r data-prep}
# Write code to filter and clean the data
# Filter the dataset into two groups: recovered and non-recovered patients
recovered_patients <- subset(covid_data, recovered == "1")
non_recovered_patients <- subset(covid_data, recovered == "0")

# Remove rows with missing values only in the 'age' column for both subsets
recovered_patients <- recovered_patients[!is.na(recovered_patients$age), ]
non_recovered_patients <- non_recovered_patients[!is.na(non_recovered_patients$age), ]

# Print the number of rows in each group
cat("Number of recovered patients (after removing missing age):", nrow(recovered_patients), "\n")
cat("Number of non-recovered patients (after removing missing age):", nrow(non_recovered_patients), "\n")
```

### Step 3: Assess Normality

- Use a histogram and a Shapiro-Wilk test to assess the normality of age distribution for both groups.

```{r normality-test}
# Write code to assess normality
# Load necessary library for visualization and testing
library(ggplot2)

# Create histograms for age distribution of recovered and non-recovered patients
ggplot(recovered_patients, aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(
    title = "Age Distribution of Recovered Patients",
    x = "Age",
    y = "Frequency"
  ) +
  theme_minimal()

ggplot(non_recovered_patients, aes(x = age)) +
  geom_histogram(binwidth = 5, fill = "red", color = "black", alpha = 0.7) +
  labs(
    title = "Age Distribution of Non-Recovered Patients",
    x = "Age",
    y = "Frequency"
  ) +
  theme_minimal()

# Perform Shapiro-Wilk test for normality on the 'age' column for both groups
shapiro_recovered <- shapiro.test(recovered_patients$age)
shapiro_non_recovered <- shapiro.test(non_recovered_patients$age)

# Print the results of the Shapiro-Wilk test
cat("Shapiro-Wilk test for Recovered Patients:\n")
print(shapiro_recovered)

cat("\nShapiro-Wilk test for Non-Recovered Patients:\n")
print(shapiro_non_recovered)
```

1. **Does the Shapiro-Wilk test results indicated that the data follow a normal distributions?**  
2. **How does it affect our choice of statistical test?**  

**Write your answers here as free text:**

### Step 4: Perform a Mann-Whitney U Test

```{r mann-whitney-test}
# Write code to perform a Mann-Whitney U test
mann_whitney_result <- wilcox.test(recovered_patients$age, non_recovered_patients$age)

# Print the result of the Mann-Whitney U test
cat("Mann-Whitney U test result:\n")
print(mann_whitney_result)
```

### Step 5: Visualize the Results with Boxplots

- Create a boxplot to visualize the age distribution for recovered and non-recovered groups.
- Display the p-value above the boxplot.

```{r boxplot-visualization}
# Write code to create the boxplot and annotate with the p-value
# Load necessary library for visualization
library(ggplot2)

# Ensure that the 'recovered' column is treated as a factor for proper labeling
covid_data$recovered <- factor(covid_data$recovered, levels = c("0", "1"), labels = c("Non-Recovered", "Recovered"))

# Create a boxplot to visualize the age distribution for recovered and non-recovered groups
ggplot(covid_data, aes(x = recovered, y = age, fill = recovered)) +
  geom_boxplot(alpha = 0.7, color = "black") +
  scale_fill_manual(values = c("red", "steelblue")) +
  labs(
    title = "Age Distribution by Recovery Status",
    x = "Recovery Status",
    y = "Age"
  ) +
  theme_minimal() +
  theme(legend.position = "none") +  # Remove legend
  # Display the p-value above the boxplot
  annotate("text", x = 1.5, y = max(covid_data$age, na.rm = TRUE), 
           label = paste("p =", format(mann_whitney_result$p.value, digits = 3)), 
           size = 5, color = "black")
```

### Step 6: Interpret the Results

In free text, answer the following questions:

1. **Was the null hypothesis rejected?**  
2. **What do the test statistic and p-value tell us?**  
3. **Is there evidence to suggest a difference in mean age between the groups?**  

**Write your answers here as free text:**



## Task 3: Analyzing COVID-19 Mortality and Human Development Index (HDI)

In this task, we will explore the hypothesis that countries with a high Human Development Index (HDI) have a greater risk of dying from COVID-19.

### Step 1: Load the Data

- Read "owid-covid-data.csv" from the URL into a variable called `covid_world`.

```{r}
# Enter your code here:
library(readr)

# Specify the file path (update the path if necessary)
file_path <- "owid-covid-data.csv"

# Load the dataset
covid_world <- read_csv(file_path)

# Inspect the first few rows of the dataset
head(covid_world)
```

### Step 2: Take a Look at the Data

- View the dataset.

```{r include=FALSE}
View(covid_world)
```


### Step 3: Create a Subset for Analysis

- Do the following using pipes ("%>%" or "|>") followed by the correct functions from the `tidyverse` package.
- Make a second table and call it `covid_hdi_vs_deaths`:
  1. Keep rows where `date` is equal to "2021-11-08".
  2. Select the columns: `"location"`, `"human_development_index"`, `"population"`, `"total_deaths"`.
  3. Remove rows with `NA` values.
  4. Add a column `total_deaths_per_million` that normalize the total death in each country per million (round the final value).

```{r}
# Enter your code here:
library(dplyr)

# Assuming the dataset is 'covid_world' and the 'date' column is of Date type
covid_hdi_vs_deaths <- covid_world %>%
  filter(date == as.Date("2021-11-08")) %>%                # Step 1: Filter rows for the date "2021-11-08"
  select(location, human_development_index, population, total_deaths) %>%  # Step 2: Select required columns
  drop_na() %>%                                   # Step 3: Remove rows with NA values
  mutate(total_deaths_per_million = round(total_deaths / population * 1e6, 0))  # Step 4: Add normalized death column

# View the final table
head(covid_hdi_vs_deaths)
```


### Step 4: Visualize the Relationship

- Create a scatterplot to visualize the relationship between HDI and `total_deaths_per_million`.
- Add a linear regression line to the plot using `geom_smooth`

```{r}
# Enter your code here:
library(ggplot2)

# Create a scatterplot to visualize the relationship between HDI and total_deaths_per_million
ggplot(covid_hdi_vs_deaths, aes(x = human_development_index, y = total_deaths_per_million)) +
  geom_point(color = "blue", alpha = 0.6) +  # Scatterplot points
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Linear regression line
  labs(
    title = "Relationship Between HDI and Total Deaths per Million",
    x = "Human Development Index (HDI)",
    y = "Total Deaths per Million"
  ) +
  theme_minimal()  # Minimal theme for cleaner visualization
```

### Step 5: Calculate Correlations

- Calculate the **Pearson** and **Spearman** correlation coefficients between HDI and `total_deaths_per_million`.

```{r}
# Enter your code here:
# Calculate Pearson correlation coefficient
pearson_corr <- cor(covid_hdi_vs_deaths$human_development_index, 
                    covid_hdi_vs_deaths$total_deaths_per_million, 
                    method = "pearson")

# Calculate Spearman correlation coefficient
spearman_corr <- cor(covid_hdi_vs_deaths$human_development_index, 
                     covid_hdi_vs_deaths$total_deaths_per_million, 
                     method = "spearman")

# Display the results
cat("Pearson Correlation Coefficient: ", pearson_corr, "\n")
cat("Spearman Correlation Coefficient: ", spearman_corr, "\n")
```


### Step 6: Interpret the Correlation

- Report the Pearson and Spearman correlation coefficients, the strength (weak/moderate/strong/very strong), and the direction (positive/negative).

**Write your answers here as free text:**


### Step 7: Assess the Claim

- Do you agree with the claim that increased HDI causes higher COVID-19 mortality? Write a detailed explanation.

**Write your answers here as free text:**


### Step 8: Find Another Feature

- Find another feature in `covid_world` that might explain the correlation between HDI and COVID-19 mortality.
- Plot this feature as in step 4.


```{r}
# Enter your code here:
```

### Step 9: Explain the New Finding

- Write your explanation for the relationship you found.

**Write your answers here as free text:**


## Task 4 - Sequence Alignment

- Take a look at the "Biostrings" package vignettes
```{r include=FALSE}
browseVignettes("Biostrings")
```

- Download the file "covid_spike_variants.fasta" from the course website
This file contain the amino acids sequence of the COVID-19 spike protein from different variants

- Load the file using the correct function from the package "Biostrings" and assign to a variable called "variants"
```{r}
# Enter your code here:
```

- How many amina acids are in the Alpha variant?

**Write your answers here as free text:**


- Read the documentation for the Multiple Sequence Alignment (msa) function from the package "msa"
- Run MSA for the sequences in "variants" and assign the results to "variants.msa"
```{r}
# Enter your code here:
```


- Take a look at the results using the package "msaR" (notice: you can scroll right and left to see all the sequence)
```{r}
msaR(AAMultipleAlignment(variants.msa), colorscheme = "taylor")
```

- (1) Which amino-acids appear in position #26? (type "AMINO_ACID_CODE" in the console)
- (2) Write an example of a SNP that can cause the change in amino acid as we see in the Gamma variant

**Write your answers here as free text:**


Phylogenetic tree for the COVID19 variants:
- Use the package "seqinr" to generate a distance matrix from the MSA results
```{r include=FALSE}
# Enter your code here:
```

- Plot a phylogenetic tree (dendrogram) assembled by hierarchical clustering using the "ward.D" method
```{r}
# Enter your code here:
```


- Look at the phylogenetic tree and answer the following questions:
1. Which variant is most similar to the Beta variant?
2. Which pair of variants are the closest?

**Write your answers here as free text:**


# Instructions to Knit the Homework as an HTML File Before Submission

1. Replace `<ID1>` and `<ID2>` in the YAML header with your student IDs:
   ```yaml
   title: "Homework 1"
   author: "<ID1>_<ID2>"
   date: "`r Sys.Date()`"
   output: html_document
   ```
   Example: `author: "123456789_123456789"`

2. Click the arrow next to the **Knit** button, and click **Knit to HTML**

3. Verify the output and submit the HTML file to the course website